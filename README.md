# Описание 

[MACHINE LEARNING AND PATTERN RECOGNITION](http://www.inf.ed.ac.uk/teaching/courses/mlpr/2016/) - этот курс был посвящен машинному обучению с вероятностной перспективы (bayesian way). В нем мы в основном рассматривали generative models. Задание состояло из двух частей и выполнялось на Matlab'е. Текст задания в [mlpr_assignment.pdf](./mlpr_assignment.pdf). Мой отчет лежит в [report.pdf](./report.pdf), он также содержит листинги кода с комментариями к нему - рекомендую читать именно его. Отзыв о моей работе в [MLPRFeedback.pdf](./MLPRFeedback.pdf). Оценка 98/100, выше результата в группе из более чем 50 человек не было. 

## Первая часть 
Нужно было предсказать значение черного/белого пикселя (назовем его **целевым**) по центру нижней кромки изображений тканей органов в достаточно большем приближении. По заданию мы делали это с помощью RNN и линейной регрессии. Результаты для RNN и линейной регрессии были очень близки (в рамках доверительного интервала), поэтому для последующих экспериментов я выбрал линейную регрессию, руководствуясь бритвой Окамы. Единственные приорные данные, это то что интенсивность соседних пикселей сильно коррелирует, т.к. это изображения реальных объектов в большом увеличении. Поэтому я провел кросс-валидацию радиуса вокруг целевого пикселя, чтобы определить какие близлежащие пиксели содержат наиболее полезную информацию. После этого я смог эффективно обучить линейную регрессию, и получил одно из самых низких значений ошибки для регрессии на тестовом сете в группе. 

## Вторая часть
Изучали иерархические модели и Markov chain Monte Carlo (MCMC) на примере бинарной классификации текста. Информации о тексте нет, данные сразу были даны в bug of features виде. Здесь из интересного в 2.1с, я заметил что простой линейный классификатор (без регуляризации или soft-margin как у SVM) с размерностью 100 (101 с учетом bias), должен идеально разделять 100 или менее тренировочных примеров, но этого не происходило (точность не была равна 100% на тренировачном сэте). Благодаря этому, я смог найти и очистить в данных все случаи, когда одни и тем же фичям были данные разные лейблы. Это позволило улучшить последующию точность классификации. В 2.2 интересно, как учет приорных знаний о том, что некоторые тренировочные данные неверно промаркированы (ошибки не в лейблах, но в самих фичях), позволяет увеличить точность классификации.

